import os
import secrets
import time
import json
from typing import Dict, Any, List

# Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¿Î¯ clients â€“ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Ï„Î± Ï€Î±ÎºÎ­Ï„Î±, Î±Ï€Î»Î¬ Î³Ï…ÏÎ½Î¬Î¼Îµ ÏƒÎµ local mode
try:
    import google.generativeai as genai
except ImportError:
    genai = None  # type: ignore[assignment]

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None  # type: ignore[assignment]


class ThronosAI:
    def __init__(self) -> None:
        """
        Mode:
          - "gemini"  -> Î¼ÏŒÎ½Î¿ Gemini
          - "openai"  -> Î¼ÏŒÎ½Î¿ OpenAI
          - "auto"    -> Ï€ÏÏÏ„Î± Gemini, Î¼ÎµÏ„Î¬ OpenAI, Î¼ÎµÏ„Î¬ local
          - "local"   -> ÎºÎ±Î¸ÏŒÎ»Î¿Ï… external, Î¼ÏŒÎ½Î¿ blockchain/local
        """
        self.mode = os.getenv("THRONOS_AI_MODE", "auto").lower()

        # ğŸ‘‰ ÎšÎ»ÎµÎ¹Î´Î¹Î¬: Î´Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ ÎšÎ‘Î™ GEMINI_API_KEY ÎšÎ‘Î™ GOOGLE_API_KEY (fallback)
        self.gemini_api_key = (
            os.getenv("GEMINI_API_KEY", "").strip()
            or os.getenv("GOOGLE_API_KEY", "").strip()
        )
        self.openai_api_key = os.getenv("OPENAI_API_KEY", "").strip()

        self.gemini_model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-pro")
        self.openai_model_name = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.getenv("DATA_DIR", os.path.join(base_dir, "data"))
        os.makedirs(self.data_dir, exist_ok=True)

        self.ai_history_file = os.path.join(self.data_dir, "ai_history.json")
        self.ai_block_log_file = os.path.join(self.data_dir, "ai_block_log.json")

        self.gemini_model = None        # type: ignore[assignment]
        self.openai_client = None       # type: ignore[assignment]

        # Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· providers
        self._init_gemini()
        self._init_openai()

    # â”€â”€â”€ INIT PROVIDERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _init_gemini(self) -> None:
        """Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Gemini client (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ»ÎµÎ¹Î´Î¯ + Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·)."""
        if not self.gemini_api_key or not genai:
            return
        try:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel(self.gemini_model_name)
            print(f"[ThronosAI] Gemini online ({self.gemini_model_name})")
        except Exception as e:
            print("[ThronosAI] Gemini init error:", e)
            self.gemini_model = None

    def _init_openai(self) -> None:
        """Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· OpenAI client (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ»ÎµÎ¹Î´Î¯ + Ï€Î±ÎºÎ­Ï„Î¿)."""
        if not self.openai_api_key or not OpenAI:
            return
        try:
            self.openai_client = OpenAI(api_key=self.openai_api_key)
            print(f"[ThronosAI] OpenAI online ({self.openai_model_name})")
        except Exception as e:
            print("[ThronosAI] OpenAI init error:", e)
            self.openai_client = None

    # â”€â”€â”€ UTILS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def generate_quantum_key(self) -> str:
        return secrets.token_hex(16)

    def _base_payload(self, text: str, status: str = "online") -> Dict[str, Any]:
        return {
            "response": text,
            "status": status,
            "quantum_key": self.generate_quantum_key(),
        }

    def _load_history(self) -> List[Dict[str, Any]]:
        try:
            with open(self.ai_history_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return []

    def _save_history(self, items: List[Dict[str, Any]]) -> None:
        try:
            with open(self.ai_history_file, "w", encoding="utf-8") as f:
                json.dump(items, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print("[ThronosAI] Failed to save history:", e)

    def _append_block_log(self, entry: Dict[str, Any]) -> None:
        """
        Condensed log ÏƒÏ„Î¿ ai_block_log.json.
        Î‘Ï€ÏŒ ÎµÎºÎµÎ¯ Ï„Î¿ ÏƒÎ·ÎºÏÎ½ÎµÎ¹ Whisper / Survival node Î³Î¹Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¬ blocks.
        """
        try:
            try:
                with open(self.ai_block_log_file, "r", encoding="utf-8") as f:
                    items = json.load(f)
            except Exception:
                items = []
            items.append(entry)
            with open(self.ai_block_log_file, "w", encoding="utf-8") as f:
                json.dump(items, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print("[ThronosAI] Failed to append block-log:", e)

    def _store_history(self, prompt: str, answer: Dict[str, Any], wallet: str | None) -> None:
        """Î“ÏÎ¬Ï†ÎµÎ¹ full history + condensed block log."""
        items = self._load_history()
        rec = {
            "ts": int(time.time()),
            "wallet": wallet or None,
            "prompt": prompt,
            "response": answer.get("response", ""),
            "status": answer.get("status", ""),
        }
        items.append(rec)
        if len(items) > 500:
            items = items[-500:]
        self._save_history(items)

        block_rec = {
            "ts": rec["ts"],
            "wallet": rec["wallet"],
            "prompt_hash": self._hash_short(rec["prompt"]),
            "response_hash": self._hash_short(rec["response"]),
            "status": rec["status"],
        }
        self._append_block_log(block_rec)

    def _hash_short(self, text: str) -> str:
        import hashlib
        h = hashlib.sha256(text.encode("utf-8")).hexdigest()
        return h[:24]

    # â”€â”€â”€ PROVIDERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _call_gemini(self, prompt: str) -> Dict[str, Any]:
        if not self.gemini_model:
            raise RuntimeError("Gemini model not initialized")
        try:
            resp = self.gemini_model.generate_content(prompt)
            txt = (getattr(resp, "text", "") or "").strip()
            if not txt:
                txt = "Quantum Core: empty response from Gemini."
            return self._base_payload(txt, status="gemini")
        except Exception as e:
            msg = str(e)
            if "quota" in msg.lower() or "exceeded" in msg.lower() or "429" in msg:
                return self._base_payload(
                    "Quantum Core Notice: Î¤Î¿ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏŒ AI (Gemini) Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Ï€Î»Î­Î¿Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± credits "
                    "Î® Î­Ï‡ÎµÎ¹ Î¾ÎµÏ€ÎµÏÎ±ÏƒÏ„ÎµÎ¯ Ï„Î¿ ÏŒÏÎ¹Î¿ Ï‡ÏÎ®ÏƒÎ·Ï‚. Î§ÏÎ®ÏƒÎ· Ï„Î¿Ï€Î¹ÎºÎ®Ï‚ blockchain Î³Î½ÏÏƒÎ·Ï‚.",
                    status="quota_exceeded",
                )
            return self._base_payload(
                f"Quantum Core Error (Gemini): {msg}",
                status="error",
            )

    def _call_openai(self, prompt: str) -> Dict[str, Any]:
        if not self.openai_client:
            raise RuntimeError("OpenAI client not initialized")
        try:
            completion = self.openai_client.chat.completions.create(
                model=self.openai_model_name,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "You are the Thronos Autonomous AI, integrated in a blockchain environment. "
                            "Answer concisely and in production-ready code when needed."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
            )
            txt = completion.choices[0].message.content
            txt = (txt or "").strip()
            if not txt:
                txt = "Quantum Core: empty response from OpenAI."
            return self._base_payload(txt, status="openai")
        except Exception as e:
            msg = str(e)
            if "rate limit" in msg.lower() or "quota" in msg.lower() or "429" in msg:
                return self._base_payload(
                    "Quantum Core Notice: Î¤Î¿ ÎµÎ¾Ï‰Ï„ÎµÏÎ¹ÎºÏŒ AI (OpenAI) ÎµÎ¯Î½Î±Î¹ ÏƒÎµ rate limit / quota. "
                    "Î§ÏÎ®ÏƒÎ· Ï„Î¿Ï€Î¹ÎºÎ®Ï‚ blockchain Î³Î½ÏÏƒÎ·Ï‚.",
                    status="quota_exceeded",
                )
            return self._base_payload(
                f"Quantum Core Error (OpenAI): {msg}",
                status="error",
            )

    # â”€â”€â”€ LOCAL / BLOCKCHAIN KNOWLEDGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _local_answer(self, prompt: str) -> Dict[str, Any]:
        """
        ÎŒÏ„Î±Î½ Î´ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ provider Î® quota, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ Ï„Î¿Ï€Î¹ÎºÏŒ history.
        Î‘Ï€Î»ÏŒ keyword matching, Î±Î»Î»Î¬ ÎµÎ¯Î½Î±Î¹ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.
        """
        prompt_l = prompt.lower()
        words = [w for w in prompt_l.split() if len(w) > 3]

        history = self._load_history()
        if not history:
            text = (
                "Î¤Î¿ Quantum Core Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î±ÎºÏŒÎ¼Î· Î±ÏÎºÎµÏ„Î¬ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÏ„Î¿ blockchain log.\n"
                "Î£Ï…Î½Î­Ï‡Î¹ÏƒÎµ Î½Î± Ï„Î¿Ï… Î´Î¯Î½ÎµÎ¹Ï‚ ÎµÎ½Ï„Î¿Î»Î­Ï‚ ÎºÎ±Î¹ ÎºÏÎ´Î¹ÎºÎ±Â· ÎºÎ¬Î¸Îµ ÎºÎ±Î»Î® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î±Ï€Î¿Î¸Î·ÎºÎµÏÎµÏ„Î±Î¹ Ï‰Ï‚ block Î³Î½ÏÏƒÎ·Ï‚."
            )
            return self._base_payload(text, status="local_empty")

        best = None
        best_score = -1.0

        for rec in history:
            hay = (rec.get("prompt", "") + " " + rec.get("response", "")).lower()
            score = 0
            for w in words:
                if w in hay:
                    score += 1
            # Î¼Î¹ÎºÏÏŒ Î¼Ï€ÏŒÎ½Î¿Ï…Ï‚ ÏƒÏ„Î± Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î±
            score += (rec.get("ts", 0) / 1_000_000_000.0)
            if score > best_score:
                best_score = score
                best = rec

        if not best or best_score <= 0:
            text = (
                "Î”ÎµÎ½ Î²ÏÎ®ÎºÎ± ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ block Î³Î½ÏÏƒÎ·Ï‚ ÏƒÏ„Î¿ Ï„Î¿Ï€Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿.\n"
                "Î˜Î± Ï‡ÏÎµÎ¹Î±ÏƒÏ„Î¿ÏÎ½ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Î³Î¹Î± Î½Î± Î¼Î¬Î¸ÎµÎ¹ Î±Ï…Ï„ÏŒÎ½ Ï„Î¿Î½ Ï„ÏÏ€Î¿ ÎµÏÏ‰Ï„Î®ÏƒÎµÏ‰Î½."
            )
            return self._base_payload(text, status="local_miss")

        text = (
            "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ Ï„Î¿Ï€Î¹ÎºÏŒ blockchain log (offline Î³Î½ÏÏƒÎ·):\n\n"
            + best.get("response", "")
        )
        return self._base_payload(text, status="local")

    # â”€â”€â”€ PUBLIC API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def generate_response(self, prompt: str, wallet: str | None = None) -> Dict[str, Any]:
        """
        ÎšÎµÎ½Ï„ÏÎ¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿Ï‚:
        - Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ external providers (Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î¿ mode)
        - Î‘Î½ Î­Ï‡Î¿Ï…Î½ quota / error, Ï€Î­Ï†Ï„ÎµÎ¹ ÏƒÎµ Ï„Î¿Ï€Î¹ÎºÎ® blockchain Î³Î½ÏÏƒÎ·
        - ÎŒ,Ï„Î¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î²Î³ÎµÎ¹, Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹ ÏƒÎµ history + ai_block_log.json
        """
        prompt = (prompt or "").strip()
        if not prompt:
            return self._base_payload("Empty prompt.", status="error")

        mode = self.mode

        # 1) ÎœÏŒÎ½Î¿ local
        if mode == "local":
            answer = self._local_answer(prompt)
            self._store_history(prompt, answer, wallet)
            return answer

        # 2) ÎœÏŒÎ½Î¿ Gemini
        if mode == "gemini":
            if not self.gemini_model:
                answer = self._local_answer(prompt)
            else:
                answer = self._call_gemini(prompt)
                if answer.get("status") in ("quota_exceeded", "error"):
                    local = self._local_answer(prompt)
                    local["response"] += (
                        "\n\n---\n[Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· provider]: " + answer.get("response", "")
                    )
                    answer = local
            self._store_history(prompt, answer, wallet)
            return answer

        # 3) ÎœÏŒÎ½Î¿ OpenAI
        if mode == "openai":
            if not self.openai_client:
                answer = self._local_answer(prompt)
            else:
                answer = self._call_openai(prompt)
                if answer.get("status") in ("quota_exceeded", "error"):
                    local = self._local_answer(prompt)
                    local["response"] += (
                        "\n\n---\n[Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· provider]: " + answer.get("response", "")
                    )
                    answer = local
            self._store_history(prompt, answer, wallet)
            return answer

        # 4) auto â€“ Ï€ÏÏÏ„Î± Gemini, Î¼ÎµÏ„Î¬ OpenAI, Î¼ÎµÏ„Î¬ local
        answer: Dict[str, Any] | None = None
        last_err: Dict[str, Any] | None = None

        if self.gemini_model:
            ans_g = self._call_gemini(prompt)
            if ans_g.get("status") not in ("quota_exceeded", "error"):
                answer = ans_g
            else:
                last_err = ans_g

        if answer is None and self.openai_client:
            ans_o = self._call_openai(prompt)
            if ans_o.get("status") not in ("quota_exceeded", "error"):
                answer = ans_o
            else:
                last_err = ans_o

        if answer is None:
            answer = self._local_answer(prompt)
            if last_err is not None:
                answer["response"] += (
                    "\n\n---\n[Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· provider]: " + last_err.get("response", "")
                )

        self._store_history(prompt, answer, wallet)
        return answer
