# -*- coding: utf-8 -*-
"""
Thronos AI Agent Service

- Î•Î½Î¹Î±Î¯Î¿ interface Î³Î¹Î± OpenAI / Gemini / Offline.
- ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ ÎºÎ»Î®ÏƒÎµÏ‰Î½ ÏƒÎµ ai_block_log.json.
- Î£Ï…Î¼Î²Î±Ï„ÏŒ Î¼Îµ server.py (generate_response + generate_quantum_key).
"""

import os
import json
import time
import hashlib
import random
import string
import logging
from typing import Optional, Dict, Any

import requests

# Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Ï†Î¿ÏÏ„ÏÏƒÎ¿Ï…Î¼Îµ OpenAI client (Î½Î­Î¿ SDK)
try:
    from openai import OpenAI
    _OPENAI_AVAILABLE = True
except Exception:
    _OPENAI_AVAILABLE = False

# Î‘Î½ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Ï„Î¿ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ google-genai SDK, Î¼Ï€Î¿ÏÎµÎ¯Ï‚,
# Î±Î»Î»Î¬ ÎµÎ´Ï Ï€Î¬Î¼Îµ Î¼Îµ ÎºÎ±Î¸Î±ÏÏŒ requests Î³Î¹Î±Ï„Î¯ Î­Ï„ÏƒÎ¹ ÎºÎ¹ Î±Î»Î»Î¹ÏÏ‚ Ï„Î¿ error 429
# Î®ÏÎ¸Îµ Î±Ï€ÏŒ HTTP ÎºÎ»Î®ÏƒÎ·.
# from google import genai   # Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.getenv("DATA_DIR", os.path.join(BASE_DIR, "data"))
os.makedirs(DATA_DIR, exist_ok=True)

AI_BLOCK_LOG_FILE = os.path.join(DATA_DIR, "ai_block_log.json")

logger = logging.getLogger("thronos_ai")
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)


class ThronosAI:
    def __init__(self) -> None:
        # Mode:
        #   "gemini"  -> Î¼ÏŒÎ½Î¿ Gemini
        #   "openai"  -> Î¼ÏŒÎ½Î¿ OpenAI
        #   "auto"    -> Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯ Gemini, Î¼ÎµÏ„Î¬ OpenAI, Î¼ÎµÏ„Î¬ local
        #   "local"   -> ÎºÎ±Î¸ÏŒÎ»Î¿Ï… external, Î¼ÏŒÎ½Î¿ blockchain/local
        self.mode = os.getenv("THRONOS_AI_MODE", "auto").lower()

        # ğŸ‘‰ Î”Î¹Î¬Î²Î±ÏƒÎµ ÎšÎ‘Î™ Ï„Î± Î´ÏÎ¿ Î¿Î½ÏŒÎ¼Î±Ï„Î± env, Î¼Îµ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿ GEMINI_API_KEY
        self.gemini_api_key = (
            os.getenv("GEMINI_API_KEY", "").strip()
            or os.getenv("GOOGLE_API_KEY", "").strip()
        )
        self.openai_api_key = os.getenv("OPENAI_API_KEY", "").strip()

        self.gemini_model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-pro")
        self.openai_model_name = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = os.getenv("DATA_DIR", os.path.join(base_dir, "data"))
        os.makedirs(self.data_dir, exist_ok=True)

        self.ai_history_file = os.path.join(self.data_dir, "ai_history.json")
        self.ai_block_log_file = os.path.join(self.data_dir, "ai_block_log.json")

        self.gemini_model = None
        self.openai_client = None

        self._init_gemini()
        self._init_openai()

    # ------------------------------------------------------------------ #
    #  Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ¬
    # ------------------------------------------------------------------ #
    def generate_quantum_key(self, length: int = 32) -> str:
        """ÎœÎ¹ÎºÏÏŒ, ÏŒÎ¼Î¿ÏÏ†Î¿ pseudo-ÎºÎ²Î±Î½Ï„Î¹ÎºÏŒ ÎºÎ»ÎµÎ¹Î´Î¯ Î³Î¹Î± Ï„Î¿ UI."""
        alphabet = string.hexdigits.lower()
        return "".join(random.choice(alphabet) for _ in range(length))

    def _load_log(self):
        try:
            with open(AI_BLOCK_LOG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return []

    def _save_log(self, data):
        try:
            with open(AI_BLOCK_LOG_FILE, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error("Failed to write ai_block_log.json: %s", e)

    def _append_log_entry(self, entry: Dict[str, Any]) -> Dict[str, Any]:
        """
        Î“ÏÎ¬Ï†ÎµÎ¹ Î¼Î¯Î± ÎµÎ³Î³ÏÎ±Ï†Î® ÏƒÏ„Î¿ ai_block_log.json.
        Î’Î¬Î¶Î¿Ï…Î¼Îµ id, timestamp ÎºÏ„Î» ÏÏƒÏ„Îµ Î¿ watcher Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï„Î·Î½ Î´ÎµÎ¹.
        """
        log = self._load_log()
        # default fields
        entry.setdefault("id", f"{int(time.time()*1000)}-{len(log)}")
        entry.setdefault(
            "timestamp",
            time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime())
        )
        log.append(entry)
        # ÎšÏÎ±Ï„Î¬Î¼Îµ Ï„Î± Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± 2000 Î³Î¹Î± Î½Î± Î¼Î·Î½ Î¾ÎµÏ†ÏÎ³ÎµÎ¹
        log = log[-2000:]
        self._save_log(log)
        return entry

    # ------------------------------------------------------------------ #
    #  Providers
    # ------------------------------------------------------------------ #
    def _call_gemini(self, prompt: str) -> str:
        """
        ÎšÎ»Î®ÏƒÎ· ÏƒÎµ Gemini REST API.
        Î‘Î½ Î²Î±ÏÎ­ÏƒÎµÎ¹ 429 / quota / Î¬Î»Î»Î¿ error, Ï€ÎµÏ„Î¬ÎµÎ¹ Exception.
        """
        if not self.gemini_key:
            raise RuntimeError("GEMINI_API_KEY not configured")

        url = (
            f"https://generativelanguage.googleapis.com/v1beta/models/"
            f"{self.gemini_model}:generateContent?key={self.gemini_key}"
        )

        payload = {
            "contents": [
                {"parts": [{"text": prompt}]}
            ]
        }

        r = requests.post(url, json=payload, timeout=60)
        if r.status_code != 200:
            # Î±Ï†Î®Î½Ï‰ Ï„Î¿ Î¼Î®Î½Ï…Î¼Î± ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î¿ error Ï€Î¿Ï… ÎµÎ¯Î´ÎµÏ‚, Î³Î¹Î± Î½Î± ÎµÎ¯Î½Î±Î¹ Î¿Î¹ÎºÎµÎ¯Î¿
            raise RuntimeError(
                f"Gemini HTTP {r.status_code}: {r.text[:512]}"
            )

        data = r.json()
        try:
            # ÎºÎ»Î±ÏƒÎ¹ÎºÎ® Î´Î¿Î¼Î®: candidates[0].content.parts[0].text
            candidates = data.get("candidates", [])
            if not candidates:
                raise RuntimeError("No candidates in Gemini response")
            content = candidates[0].get("content", {})
            parts = content.get("parts", [])
            if not parts:
                raise RuntimeError("No parts in Gemini response")
            text = parts[0].get("text", "")
            return text
        except Exception as e:
            raise RuntimeError(f"Gemini parse error: {e}")

    def _call_openai(self, prompt: str) -> str:
        """
        ÎšÎ»Î®ÏƒÎ· ÏƒÎµ OpenAI Chat.
        Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Î½Î­Î¿ openai SDK Î±Î½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿.
        """
        if not self.openai_key:
            raise RuntimeError("OPENAI_API_KEY not configured")

        if not self._openai_client:
            raise RuntimeError("OpenAI client not available")

        try:
            resp = self._openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "You are Thronos Autonomous AI, speaking in Greek / English "
                            "with a technical but clear tone. When user asks for code, "
                            "return FULL code snippets and, when appropriate, embed "
                            "FILE blocks of the form:\n"
                            "[[FILE:filename.ext]]\n<content>\n[[/FILE]]\n"
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                max_tokens=2048,
            )
            text = resp.choices[0].message.content
            return text
        except Exception as e:
            raise RuntimeError(f"OpenAI error: {e}")

    def _offline_reply(self, prompt: str) -> str:
        """
        Fallback ÏŒÏ„Î±Î½ Î´ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ ÎºÎ±Î¸ÏŒÎ»Î¿Ï… API Î® ÏŒÎ»Î± Î²Î±ÏÎ¬Î½Îµ error.
        Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î¼Î¿Î½Ï„Î­Î»Î¿, ÎµÎ¯Î½Î±Î¹ Î±Ï€Î»Î¬ Î¬Î½Î¸ÏÏ‰Ï€Î¿Ï‚-Î³ÏÎ±Î¼Î¼Î±Ï„Î­Î±Ï‚ Î¼Îµ Ï‡Î¹Î¿ÏÎ¼Î¿Ï.
        """
        base = (
            "[OFFLINE CORE]\n"
            "Î¤Î¿ ÎºÎµÎ½Ï„ÏÎ¹ÎºÏŒ AI backend Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Î±Ï…Ï„Î® Ï„Î· ÏƒÏ„Î¹Î³Î¼Î® "
            "(quota, Î´Î¯ÎºÏ„Ï…Î¿ Î® ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚). "
            "Î˜Î± ÏƒÎ¿Ï… Î±Ï€Î±Î½Ï„Î®ÏƒÏ‰ Î¼Îµ Î­Î½Î± Î±Ï€Î»ÏŒ, ÏƒÏ„Î±Ï„Î¹ÎºÏŒ Î¼Î®Î½Ï…Î¼Î±:\n\n"
        )
        tail = (
            "â€¢ ÎœÏ€Î¿ÏÎµÎ¯Ï‚ Î½Î± Î¾Î±Î½Î±Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÎµÎ¹Ï‚ ÏƒÎµ Î»Î¯Î³Î¿.\n"
            "â€¢ Î‰ Î½Î± ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÏƒÏ‰ÏƒÏ„Î¬ Ï„Î± API keys (Gemini / OpenAI) "
            "ÏƒÏ„Î¿Î½ server.\n"
        )
        return base + tail

    # ------------------------------------------------------------------ #
    #  Public API
    # ------------------------------------------------------------------ #
    def generate_response(self, prompt: str, wallet: Optional[str] = None) -> Dict[str, Any]:
        """
        Î•Î½Î¹Î±Î¯Î¿ entrypoint Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿Î½ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ provider,
        logÎ¬ÏÎµÎ¹ ÏƒÏ„Î¿ ai_block_log.json, ÎºÎ±Î¹ Î³Ï…ÏÎ½Î¬ dict Î³Î¹Î± Ï„Î¿ /api/chat.
        """
        provider = None
        model = None
        text = ""
        status = "secure"
        error_msg = None

        # 1. Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î¼Îµ ÏƒÎµÎ¹ÏÎ¬ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±Ï‚
        try:
            if self.gemini_key:
                provider = "gemini"
                model = self.gemini_model
                text = self._call_gemini(prompt)
            elif self.openai_key and self._openai_client:
                provider = "openai"
                model = self.openai_model
                text = self._call_openai(prompt)
            else:
                provider = "offline"
                model = "thronos-offline"
                text = self._offline_reply(prompt)
        except Exception as e:
            # Î±Î½ Î­ÏƒÎºÎ±ÏƒÎµ Ï„Î¿ Ï€ÏÏÏ„Î¿, Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î´ÎµÏÏ„ÎµÏÎ¿ provider
            error_msg = str(e)
            logger.error("Primary AI provider error: %s", e)

            if provider == "gemini" and self.openai_key and self._openai_client:
                try:
                    provider = "openai"
                    model = self.openai_model
                    text = self._call_openai(prompt)
                    error_msg = None  # Î´ÎµÏÏ„ÎµÏÎ· Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï€Î­Ï„Ï…Ï‡Îµ
                except Exception as e2:
                    logger.error("Fallback OpenAI error: %s", e2)
                    error_msg = f"{error_msg} | Fallback: {e2}"
                    provider = "offline"
                    model = "thronos-offline"
                    text = self._offline_reply(prompt)
            elif provider == "openai" and self.gemini_key:
                try:
                    provider = "gemini"
                    model = self.gemini_model
                    text = self._call_gemini(prompt)
                    error_msg = None
                except Exception as e2:
                    logger.error("Fallback Gemini error: %s", e2)
                    error_msg = f"{error_msg} | Fallback: {e2}"
                    provider = "offline"
                    model = "thronos-offline"
                    text = self._offline_reply(prompt)
            else:
                # Î´ÎµÎ½ ÎµÎ¯Ï‡Î±Î¼Îµ ÎºÎ±Î½Î­Î½Î± provider Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ ÎµÎ¾Î±ÏÏ‡Î®Ï‚
                provider = provider or "offline"
                model = model or "thronos-offline"
                text = self._offline_reply(prompt)

        if error_msg:
            status = "error"

        # 2. ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® ÏƒÏ„Î¿ ai_block_log.json
        entry = {
            "wallet": wallet or "",
            "prompt": prompt,
            "response": text,
            "provider": provider,
            "model": model,
            "status": status,
            "error": error_msg,
        }
        entry = self._append_log_entry(entry)

        # 3. Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î³Î¹Î± Ï„Î¿ /api/chat
        resp = {
            "response": text,
            "quantum_key": self.generate_quantum_key(),
            "status": status,
            "wallet": wallet or "",
            "provider": provider,
            "model": model,
            "id": entry.get("id"),
        }
        if error_msg:
            resp["error"] = error_msg
        return resp
